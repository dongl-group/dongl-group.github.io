<!--<!doctype html>
<html>-->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <link rel="Shortcut Icon" href="./logo/hp_logo.jpg" sizes=16x16 type="image/x-icon"/>
        <link rel="Bookmark" href="./logo/hp_logo.jpg" sizes=16x16 type="image/x-icon"/>
        <title>dongl-group</title>
        <style>
            @media screen and (max-device-width: 480px){
    body{
    -webkit-text-size-adjust: none;
  }
}
p { font-size : 16px; }
h1 { font-size : 34px; margin : 0; padding : 0; }
h2 { font-size : 20px; margin : 0; padding : 0; }
h3 { font-size : 18px; margin : 8; padding : 0; }
lr {font-size : 14px;}
body { padding : 0; font-family : Arial; font-size : 16px; }
.title { width : 650px; margin : 20px auto; }
.container { width :70%; margin : 20px 0 0 0; border-radius: 0px; float:left; background-color : #fff; padding : 20px;  clear:both;}
.container div{margin : 10px auto;}
.members{width: 55%;background:#ffffff;display: block;float:right; margin: 20px  ;clear:both;padding-top: 20px;
}
#bio {
    padding-top : 40px;
}
#me { border : 0 solid black; margin-bottom : 50px; border-radius : 10px; }
#sidebar { margin-left : 25px; border : 0 solid black; float : right; margin-bottom : 0;}
a { text-decoration : none; }
a:hover { text-decoration : underline; }
a, a:visited { color : #0050e7; }
.publogo { width: 100 px; margin-right : 10px; float : left; border : 0;}
.publication { clear : left; padding-bottom : 0px; }
.publication p { height : 100px; padding-top : 0px; font-weight: normal;}
.publication strong a { color : #0000A0; }
.publication .links { position :relative ; top : 10px }
.publication .links a { margin-right : 5px; font-size: 15px; font-weight: normal}
.codelogo { margin-right : 10px; float : left; border : 0;}
.code { clear : left; padding-bottom : 10px; vertical-align :middle;}
.code .download a { display : block; margin : 0 15px; float : left;}
.code strong a { color : #000; }
.external a { margin : 0 10px; }
.external a.first { margin : 0 10px 0 0; }
li, ul {font-weight: normal;}

        </style>
        <link rel="stylesheet" href="stylesheets/style.css">
        <link rel="stylesheet" href="stylesheets/pygment_trac.css">
        <meta name="viewport" content="width=device-width">
        <script async="" src="./analytics.js"></script>
</head>

<body>
   <div><center><img src="logo/h_logo.png" border="0"  height="300px" width="100%"></center></div>

   <div class="wrapper">
    <header>
    <div class="members">
        <div><h2> &nbsp;&nbsp;Members:</h2></div>
        <div>
            <ul>
            <li><b>üî∏Dong Liang</b></li>
            <li><b>Ê¢ÅÊ†ã</b></li>
            <li>Associate Professor, Computer Science, Nanjing University of Aeronautics and Astronautics</li>
            <li>Email: liangdong@nuaa.edu.cn</li>
            </ul>
            <ol>
            <li>
            <p><a href="https://scholar.google.com/citations?user=oKE2Wx8AAAAJ&hl=zh-CN&oi=sra" target="_blank">[Google Scholar]</a>
            <a href="Resume/Dong LIANG.pdf" target="_blank">[Resume]</a>
            <a href="http://faculty.nuaa.edu.cn/liangdong/zh_CN/index.htm" target="_blank">[È¶ñÈ°µ]</a></p>
            </li>
            </ol>
        </div>
        <div>
            <ul>
                <a href="" target="_blank"><li><b>Yun DuÔºàÊùú‰∫ëÔºâ</b></li></a>
            <li>Email: </li>
            </ul>
        </div>
        <div>
            <ul>
                <a href="" target="_blank"><li><b>Ling LiÔºàÊùéÈìÉÔºâ</b></li></a>
            <li>Email: </li>
            </ul>
        </div>
        <div>
            <ul>
                <a href="" target="_blank"><li><b>Biaoyi XuÔºàÂæêÊ†áÂºÇÔºâ</b></li></a>
            <li>Email: </li>
            </ul>
        </div>
        <div>
            <ul>
                <a href="" target="_blank"><li><b>Mengyu QiuÔºà‰ªáÊ¢¶Èõ®Ôºâ</b></li></a>
            <li>Email: </li>
            </ul>
        </div>
        <div>
            <ul>
                <a href="" target="_blank"><li><b>Jingwei ZhangÔºàÂº†Â©ßÁÇúÔºâ</b></li></a>
            <li>Email: </li>
            </ul>
        </div>
        <div>
            <ul>
                <a href="" target="_blank"><li><b>Yachao LiÔºàÊùéÈõÖË∂ÖÔºâ</b></li></a>
            <li>Email: </li>
            </ul>
        </div>
        <div>
            <ul>
                <a href="" target="_blank"><li><b>Yue SunÔºàÂ≠ôÊÇ¶Ôºâ</b></li></a>
            <li>Email: </li>
            </ul>
        </div>
        <div>
            <ul>
                <a href="" target="_blank"><li><b>Yuanhang GaoÔºàÈ´òËøúËà™Ôºâ</b></li></a>
            <li>Email: </li>
            </ul>
        </div>
        <div>
            <ul>
                <a href="" target="_blank"><li><b>Zhengyan XuÔºàÂæêÂ≥•Â≤©Ôºâ</b></li></a>
            <li>Email: </li>
            </ul>
        </div>
        <div>
            <ul>
                <a href="" target="_blank"><li><b>Siyi ChenÔºàÈôàÊÄùÊáøÔºâ</b></li></a>
            <li>Email: </li>
            </ul>
        </div>

    </div>

</header>
    <section>
    <div class="container">
    <div>
        <h1>Welcome to our Homepage!</h1>
        <p>We are one of the research groups in MIIT Key Laboratory of Pattern Analysis and Machine Intelligence at College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics.
            Our group currently has 10 graduate students and several undergraduate students conducting experimental research under the guidance of Mr. Liang. Our research interests mainly include computer vision and machine learning, pattern recognition and intelligent systems, computational photography, and human-computer interaction theory and application research.
            <br>We have listed our published papers in recent years below for your review.
        </p>
    </div>


<h2>
    Selected Publications:</h2>
    <br>

    <!--=================*******==========================-->
    <div class="publication">
            <img src="logo/SCL-LLE.png" onmouseover="this.src='logo/SCL-LLE.png';" onmouseout="this.src='logo/SCL-LLE.png';" class="publogo"  width="300 px" HEIGHT="170PX">
            <p>
                <strong>
                    <a href="https://ojs.aaai.org/index.php/AAAI/article/view/20046">Semantically Contrastive Learning for Low-light Image Enhancement</a>
                </strong>
          <br>
		<em><b>AAAI  2022</b></em>
                <br>
                <b>Dong Liang</b>, Ling Li, Mingqiang Wei, Shuo Yang, Liyan Zhang, Wenhan Yang, Yun Du, Huiyu Zhou
                <br>
                <span class="links">
                    <a href="https://ojs.aaai.org/index.php/AAAI/article/view/20046">PDF</a> |
		            <a href="project_pages/SCL-LLE.html">Project Page</a> |
                    <a href="https://github.com/LingLIx/SCL-LLE">Code</a>
                </span>
            </p>
        </div>
    <br>
    <br>
	<br>
	<br />
	<br />
	<br />
    <!--=================*******==========================-->
    <div class="publication">
            <img src="logo/DEA-Net.png" onmouseover="this.src='logo/DEA-Net.png';" onmouseout="this.src='logo/DEA-Net.png';" class="publogo"  width="300 px" HEIGHT="180PX">
            <p>
                <strong>
                    <a href="https://ieeexplore.ieee.org/abstract/document/9654160">Anchor Retouching via Model Interaction for Robust Object Detection in Aerial Images</a>
                </strong>
          <br>
		<em><b>IEEE Transactions on Geoscience and Remote Sensing  2022</b></em>
                <br>
                <b>Dong Liang</b>, Qixiang Geng, Zongqi Wei, Dmitry A Vorontsov, Ekaterina L Kim, Mingqiang Wei, Huiyu Zhou
                <br>
                <span class="links">
                    <a href="https://ieeexplore.ieee.org/abstract/document/9654160">PDF</a>|
                    <a href="project_pages/DEA-Net.html">Project Page</a>|
                    <a href="https://github.com/QxGeng/DEA-Net">Code</a>
                </span>
            </p>
        </div>
    <br>
    <br>
	<br>
	<br />
	<br />
	<br />
    <!--=================*******==========================-->
    <div class="publication">
            <img src="logo/CG-Net.png" onmouseover="this.src='logo/CG-Net.png';" onmouseout="this.src='logo/CG-Net.png';" class="publogo"  width="300 px">
            <p>
                <strong>
                    <a href="https://ieeexplore.ieee.org/abstract/document/9735375">Learning calibrated-guidance for object detection in aerial images</a>
                </strong>
          <br>
		<em><b>IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing   2022</b></em>
                <br>
                Zongqi Wei, <b>Dong Liang</b>, Dong Zhang, Liyan Zhang, Qixiang Geng, Mingqiang Wei, Huiyu Zhou
                <br>
                <span class="links">
                    <a href="https://ieeexplore.ieee.org/abstract/document/9735375">PDF</a>|
<!--		            <a href="">Project Page</a>|-->
                    <a href="https://github.com/WeiZongqi/CG-Net">Code</a>
                </span>
            </p>
        </div>
    <br>
    <br>
	<br>
	<br />
	<br />
    <br />
    <!--=================*******==========================-->
    <div class="publication">
            <img src="logo/PRICAI 2022.png" onmouseover="this.src='logo/PRICAI 2022.png';" onmouseout="this.src='logo/PRICAI 2022.png';" class="publogo"  width="300 px">
            <p>
                <strong>
                    <a href="https://link.springer.com/chapter/10.1007/978-3-031-20868-3_43">More Than Accuracy: An Empirical Study of Consistency Between Performance and Interpretability</a>
                </strong>
          <br>
		<em><b>PRICAI 2022 </b></em>
                <br>
              Yun Du, <b>Dong Liang</b>, Rong Quan, Songlin Du, Yaping Yan .
                <br>
                <span class="links">
                    <a href="https://link.springer.com/chapter/10.1007/978-3-031-20868-3_43">PDF</a>|
<!--		            <a href="">Project Page</a>|-->
<!--                    <a href="">Code</a>-->
                </span>
            </p>
        </div>
    <br>
    <br>
	<br>
	<br />
	<br />
	<br />
    <!--=================*******==========================-->

   <div class="publication">
            <img src="logo/MTA 2022.png" onmouseover="this.src='logo/MTA 2022.png';" onmouseout="this.src='logo/MTA 2022.png';" class="publogo"  width="300 px">
            <p>
                <strong>
                    <a href="https://link.springer.com/article/10.1007/s11042-022-12319-y">Inferred box harmonization and aggregation for degraded face detection in crowds</a>
                </strong>
		  <br>
		<em><b>Multimedia Tools and Applications, 2022</b></em>
                <br>
              <b>Dong Liang</b>, Qixiang Geng, Han Sun, Huiyu Zhou, Shun‚Äôichi Kaneko.
                <br>
                <span class="links">
                    <a href="https://link.springer.com/article/10.1007/s11042-022-12319-y">PDF</a>|
<!--		            <a href="">Project Page</a>|-->
                    <a href="https://github.com/QxGeng/Co-occurrence">Code</a>|
                    <a href="https://github.com/QxGeng/Crowd-Face">Dataset</a>
                </span>
            </p>
          </div>
    <br>
    <br>
	<br>
	<br />
	<br />
	<br />
<!--=================*******==========================-->
    <div class="publication">
            <img src="logo/Robust RGB-T.png" onmouseover="this.src='logo/Robust RGB-T.png';" onmouseout="this.src='logo/Robust RGB-T.png';" class="publogo"  width="300 px">
            <p>
                <strong>
                    <a href="https://ieeexplore.ieee.org/abstract/document/9756634">Robust RGB-T Tracking via Graph Attention-Based Bilinear Pooling</a>
                </strong>
          <br>
		<em><b>IEEE Transactions on Neural Networks and Learning Systems 2022</b></em>
                <br>
              Bin Kang, <b>Dong Liang</b>, Junxi Mei, Xiaoyang Tan, Quan Zhou, Dengyin Zhang
                <br>
                <span class="links">
                    <a href="https://ieeexplore.ieee.org/abstract/document/9746588">PDF</a>|
<!--		            <a href="">Project Page</a>|-->
<!--                    <a href="">Code</a>-->
                </span>
            </p>
        </div>
    <br>
    <br>
	<br>
	<br />
	<br />
	<br />
<!--=================*******==========================-->
	<div class="publication">
            <img src="logo/FTU.png" onmouseover="this.src='logo/FTU.png';" onmouseout="this.src='logo/FTU.png';" class="publogo"  width="300 px" >
            <p>
                <strong>
                    <a href="https://www.mdpi.com/2076-3417/12/3/1061">An Effectively Finite-Tailed Updating for Multiple Object Tracking in Crowd Scenes</a>
                </strong>
          <br>
		<em><b>Applied Sciences  2022</b></em>
                <br>
                Biaoyi Xu, <b>Dong Liang</b>, Ling Li, Rong Quan, Mingguang Zhang
                <br>
                <span class="links">
                    <a href="https://www.mdpi.com/2076-3417/12/3/1061">PDF</a>|
<!--		            <a href="">Project Page</a>|-->
<!--                    <a href="">Code</a>-->
                </span>
            </p>
        </div>
    <br>
    <br>
    <br>
	<br />
	<br />
<!--=================*******==========================-->
    <div class="publication">
            <img src="logo/crowd-face.png" onmouseover="this.src='logo/crowd-face.png';" onmouseout="this.src='logo/crowd-face.png';" class="publogo"  width="300 px" >
            <p>
                <strong>
                    <a href="https://ieeexplore.ieee.org/abstract/document/9667044">Dense Face Detection via High-level Context Mining</a>
                </strong>
          <br>
		<em><b>FG 2021</b></em>
                <br>
                Qixiang Geng, <b>Dong Liang</b>, Huiyu Zhou, Liyan Zhang, Han Sun, Ningzhong Liu
                <br>
                <span class="links">
                    <a href="https://ieeexplore.ieee.org/abstract/document/9667044">PDF</a>|
<!--		            <a href="">Project Page</a>|-->
                    <a href="https://github.com/QxGeng/Crowd-Face">Code</a>
                </span>
            </p>
        </div>
    <br>
    <br>
    <br>
	<br />
	<br />
<!--=================*******==========================-->
    <div class="publication">
            <img src="logo/Cross-scene_fs.png" onmouseover="this.src='logo/Cross-scene_fs.png';" onmouseout="this.src='logo/Cross-scene_fs.png';" class="publogo"  width="300 px" height="180px">
            <p>
                <strong>
                    <a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320321001825">Cross-scene foreground segmentation with supervised and unsupervised model communication</a>
                </strong>
          <br>
		<em><b>Pattern Recognition 2021</b></em>
                <br>
                <b>Dong Liang</b>, Bin Kang, Xinyu Liu, Pan Gao, Xiaoyang Tan, Shun‚Äôichi Kaneko
                <br>
                <span class="links">
                    <a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320321001825">PDF</a>|
<!--		            <a href="">Project Page</a>|-->
                    <a href="">Code</a>
                </span>
            </p>
        </div>
    <br>
    <br>
    <br>
	<br />
	<br />
	<br />
<!--=================*******==========================-->
    <div class="publication">
            <img src="logo/HOFAM.png" onmouseover="this.src='logo/HOFAM.png';" onmouseout="this.src='logo/HOFAM.png';" class="publogo"  width="300 px" height="180px">
            <p>
                <strong>
                    <a href="https://ieeexplore.ieee.org/abstract/document/9428086">Robust Cross-Scene Foreground Segmentation in Surveillance Video</a>
                </strong>
          <br>
		<em><b>ICME 2021</b></em>
                <br>
                <b>Dong Liang</b>, Zongqi Wei, Han Sun, Huiyu Zhou
                <br>
                <span class="links">
                    <a href="https://ieeexplore.ieee.org/abstract/document/9428086">PDF</a>|
<!--		            <a href="">Project Page</a>|-->
                    <a href="https://github.com/WeiZongqi/HOFAM">Code</a>
                </span>
            </p>
        </div>
    <br>
    <br>
    <br>
	<br />
	<br />
<!--=================*******==========================-->
    <div class="publication">
            <img src="logo/NLKD.png" onmouseover="this.src='logo/NLKD.png';" onmouseout="this.src='logo/NLKD.png';" class="publogo"  width="300 px" >
            <p>
                <strong>
                    <a href="https://ieeexplore.ieee.org/abstract/document/9414355">Nlkd: using coarse annotations for semantic segmentation based on knowledge distillation</a>
                </strong>
          <br>
		<em><b>ICASSP 2021</b></em>
                <br>
                <b>Dong Liang</b>, Yun Du, Han Sun, Liyan Zhang, Ningzhong Liu, Mingqiang Wei
                <br>
                <span class="links">
                    <a href="https://ieeexplore.ieee.org/abstract/document/9414355">PDF</a>|
<!--		            <a href="">Project Page</a>|-->
<!--                    <a href="">Code</a>-->
                </span>
            </p>
        </div>
    <br>
    <br>
    <br>
	<br />
	<br />
<!--=================*******==========================-->
    <div class="publication">
        <img src="logo/CMOD.png" onmouseover="this.src='logo/CMOD.png';" onmouseout="this.src='logo/CMOD.png';" class="publogo"  width="300 px" >
            <p>
                <strong>
                    <a href="https://www.mdpi.com/2076-3417/11/23/11241">A Hard Example Mining Approach for Concealed Multi-Object Detection of Active Terahertz Image</a>
                </strong>
          <br>
		<em><b>Applied Sciences 2021</b></em>
                <br>
                Ling Li, Fei Xue, <b>Dong Liang</b>, Xiaofei Chen
                <br>
                <span class="links">
                    <a href="https://www.mdpi.com/2076-3417/11/23/11241">PDF</a>|
<!--		            <a href="">Project Page</a>|-->
<!--                    <a href="">Code</a>|-->
                    <a href="https://github.com/LingLIx/THz_Dataset">Dataset</a>
                </span>
            </p>
        </div>
    <br>
    <br>
    <br>
	<br />
	<br />

    <!--    <div class="publication">-->
<!--            <img src="logo/ICASSP 2022.png" onmouseover="this.src='logo/ICASSP 2022.png';" onmouseout="this.src='logo/ICASSP 2022.png';" class="publogo"  width="300 px">-->
<!--            <p>-->
<!--                <strong>-->
<!--                    <a href="https://ieeexplore.ieee.org/abstract/document/9746588">MBA-RainGAN: A Multi-Branch Attention Generative Adversarial Network for Mixture of Rain Removal</a>-->
<!--                </strong>-->
<!--          <br>-->
<!--		<em><b>ICASSP 2022</b></em>-->
<!--                <br>-->
<!--              Yiyang Shen, Yidan Feng, Weiming Wang, <b>Dong Liang</b>, Jing Qin, Haoran Xie, Mingqiang Wei-->
<!--                <br>-->
<!--                <span class="links">-->
<!--                    <a href="https://ieeexplore.ieee.org/abstract/document/9746588">PDF</a>|-->
<!--		            <a href="">Project Page</a>|-->
<!--                    <a href="">Code</a>-->
<!--                </span>-->
<!--            </p>-->
<!--        </div>-->
<!--    <br>-->
<!--    <br>-->
<!--	<br>-->
<!--	<br />-->
<!--	<br />-->
<!--	<br />-->





<!--<h2>-->
<!--<a id="new-page" class="anchor" href="#new-page" aria-hidden="true"><span class="octicon octicon-link"></span></a>Events:</h2>-->

<!--<div class="publication">-->
<!--           <img src="./logo/MIPI_2023.png" class="publogo" width="300 px">-->
<!--            <p>-->
<!--                <strong>-->
<!--                    <a href="">Mobile Intelligent Photography & Imaging</a>-->
<!--                </strong>-->
<!--		  <br>-->
<!--		<em><b>2nd MIPI workshop @ CVPR 2023</b></em>-->
<!--                <br>-->
<!--              <b>Chongyi Li</b>, Shangchen Zhou, Ruicheng Feng,  Yuekun Dai, Qingpeng Zhu, Qianhui Sun,  Wenxiu Sun,  Chen Change Loy, and Jinwei Gu.-->
<!--                <br>-->
<!--                <span class="links">-->
<!--		      <a href="https://mipi-challenge.org/MIPI2023/">Website</a>-->

<!--                </span>-->
<!--            </p>-->
<!--          </div>-->
<!--          <br>-->
<!--          <br>-->
<!--	<br />-->
<!--	<br />-->

<!--<div class="publication">-->
<!--            <img src="logo/codeformer1.jpg" onmouseover="this.src='logo/codeformer2.jpg';" onmouseout="this.src='logo/codeformer1.jpg';" class="publogo"  width="300 px">-->
<!--            <p>-->
<!--                <strong>-->
<!--                    <a href="">Try Your Face (face restoration platform)</a>-->
<!--                </strong>-->
<!--              We provide our code of CodeFormer (Towards Robust Blind Face Restoration with Codebook Lookup TransFormer) on Colab. Please feel free to try your face.-->
<!--                <br>-->
<!--                <span class="links">-->
<!--		      <a href="https://colab.research.google.com/drive/1m52PNveE4PBhYrecj34cnpEeiHcC5LTb?usp=sharing">Colab</a>-->

<!--                </span>-->
<!--            </p>-->
<!--          </div>-->
<!--          <br>-->
<!--	  <br>-->
<!--	<br />-->
<!--	<br />-->
<!--	<br />-->

<!--<div class="publication">-->
<!--            <img src="logo/plateform1.jpg" onmouseover="this.src='logo/plateform2.jpg';" onmouseout="this.src='logo/plateform1.jpg';" class="publogo"  width="300 px">-->
<!--            <p>-->
<!--                <strong>-->
<!--                    <a href="">Low-Light Image Enhancement Online Platform</a>-->
<!--                </strong>-->
<!--              Different algorithms demand various configurations, GPU versions, and hardware specifications that are prohibitive to beginners who are new to this area and may not even have GPU resources. We contribute an online plateform.-->
<!--                <br>-->
<!--                <span class="links">-->
<!--		      <a href="http://mc.nankai.edu.cn/ll/">Website</a>-->

<!--                </span>-->
<!--            </p>-->
<!--          </div>-->
<!--          <br>-->
<!--	  <br>-->
<!--	<br />-->
<!--	<br />-->
<!--	<br />-->

<!--	  <div class="publication">-->
<!--           <img src="./logo/MIPI.png" class="publogo" width="300 px">-->
<!--            <p>-->
<!--                <strong>-->
<!--                    <a href="">Mobile Intelligent Photography & Imaging</a>-->
<!--                </strong>-->
<!--		  <br>-->
<!--		<em><b>1st MIPI workshop @ ECCV 2022</b></em>-->
<!--                <br>-->
<!--              <b>Chongyi Li</b>, Shangchen Zhou, Ruicheng Feng, Jun Jiang, Wenxiu Sun, Qingyu Yang, Qingpeng Zhu, Chen Change Loy, and Jinwei Gu.-->
<!--                <br>-->
<!--                <span class="links">-->
<!--		      <a href="https://mipi-challenge.org/MIPI2022/">Website</a>-->

<!--                </span>-->
<!--            </p>-->
<!--          </div>-->
<!--          <br>-->
<!--          <br>-->
<!--	<br />-->
<!--	<br />-->

<!--<ul>-->
<!--<li><a href="http://mipi-challenge.org/" target="_blank"><font color="#A52A2A">[Workshop]</font></a> ECCV 2022 Workshop on Mobile Intelligent Photography and Imaging (MIPI)</a></li>-->
<!--<li><a href="https://attend.ieee.org/mmsp-2022/special-sessions/underwater-multimedia-processing/" target="_blank"><font color="#A52A2A">[Special Session]</font></a> IEEE MMSP 2022 Special Session on Underwater Multimedia Processing</a></li>-->
<!--<li><a href="https://www.frontiersin.org/research-topics/39049/multimodal-intelligence" target="_blank"><font color="#A52A2A">[Special Issue]</font></a> Frontiers in Signal Processing Special Issue on Multimodal Intelligence</a></li>-->
<!--<li><a href="https://ieeeoes.org/wp-content/uploads/2021/07/JOE_cfp_AMLM.pdf" target="_blank"><font color="#A52A2A">[Special Issue]</font></a> IEEE Journal of Oceanic Engineering Special Issue on Advanced Machine Learning Methodologies for Underwater Image and Video Processing and Analysis (2021-2022)</a></li>-->
<!--<li><a href="https://github.com/Li-Chongyi/PAPERS/blob/master/MTAP_SI_CFP.pdf" target="_blank"><font color="#A52A2A">[Special Issue]</font></a> Multimedia Tools and Applications Special Issue on Depth-Related Processing and Applications in Visual Systems (2020-2021)</a></li>-->
<!--<li><a href="https://github.com/Li-Chongyi/PAPERS/blob/master/SPIC_SI_cfp.pdf" target="_blank"><font color="#A52A2A">[Special Issue]</font></a> Signal Processing : Image Communication Special Issue on Visual Information Processing for Underwater Images and Videos: Theories, Algorithms, and Applications (2019-2020)</a></li>-->
<!--<li><a href="https://github.com/Li-Chongyi/PAPERS/blob/master/APSIPA-ASC-2019-CfP.pdf" target="_blank"><font color="#A52A2A">[Special Session]</font></a> APSIPA ASC 2019 Special Session on Multi-source Data Processing and Analysis: Models, Methods and Applications (2019-2020)</a></li>-->

<!--</ul>-->
<!--<br>-->
<!--<hr />-->



<!-- <h2>-->
<!--<a id="new-page" class="anchor" href="#new-page" aria-hidden="true"><span class="octicon octicon-link"></span></a>Honors & Awards:</h2>-->

<!--<ul>-->
<!--<li>IEEE Signal Processing Society's top-25 most downloaded articles on IEEE Xplore¬Æ, Sept. 2021 - Sept. 2022.-->
<!--<li>Pattern Recognition (Elsevier Journal) <a href="./PDF/PR_honorable mention_2020.pdf">(Best Paper Honourable Mention)</a></li>-->
<!--<li> Our team Feedforward won the <strong>second runner-up (3/317)</strong> in <a href="https://studio.brainpp.com/competition/5?name=2022%20MegCup%20%E7%82%BC%E4%B8%B9%E5%A4%A7%E8%B5%9B&tab=rank" target="_blank"><font color="#ff0000">MegCup Efficient Model for Blind Denoising</font></a>. Congrats to Xin Jin, Ruiqi Wu, and Zhen Li. The code is publicly available <a href="https://github.com/Srameo/megcup-feedforward" target="_blank"><font color="#ff0000">here.</font></a></li>-->
<!--<li><strong>World‚Äôs Top 2% Scientists (2022)</strong>. It is compiled by Stanford University based on the standardized citation indicators (Table_1_Authors_singleyr_2021_pubs_since_1788_wopp_extracted_202209), which is avaiable online at <a href="https://elsevier.digitalcommonsdata.com/datasets/btchxktzyw/4" target="_blank"><font color="#ff0000">Mendeley Database.</font></a></li>-->
<!--<li><strong>World‚Äôs Top 2% Scientists (2021)</strong>. It is compiled by Stanford University based on the standardized citation indicators (Table_1_Authors_singleyr_2020_wopp_extracted_202108), which is avaiable online at <a href="https://elsevier.digitalcommonsdata.com/datasets/btchxktzyw/3" target="_blank"><font color="#ff0000">Mendeley Database.</font></a></li>-->
<!--&lt;!&ndash;<<li>2021 Innovation in Information Technology Application and Artificial Intelligent Academic Forum for Post-doctoral Talents, Tianjin, China. Runners-up Award. <a href="PDF/postdoc_runner-up.jpg"  target="_blank">PDF</a></li>&ndash;&gt;-->
<!--<li>ECCV (Outstanding Reviewer in 2022). <a href="https://eccv2022.ecva.net/program/outstanding-reviewers/"  target="_blank">PDF</a></li>-->
<!--<li>ICCV (Outstanding Reviewer in 2021). <a href="http://iccv2021.thecvf.com/outstanding-reviewers"  target="_blank">PDF</a></li>-->
<!--<li>CVPR (Outstanding Reviewer in 2021). <a href="http://cvpr2021.thecvf.com/node/184"  target="_blank">PDF</a></li>-->
<!--<li>IEEE Journal of Oceanic Engineering (Outstanding Reviewer in 2021) <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9756533">News</a></li>-->
<!--&lt;!&ndash;<<li>6th, NTIRE 2021 Challenge on Non-Homogeneous Image Dehazing, 2021. <a href="https://github.com/Li-Chongyi/PAPERS/blob/master/NTIRE2021_NonHomogeneous_Dehazing_Report_compressed.pdf" target="_blank">PDF</a></li>&ndash;&gt;-->
<!--&lt;!&ndash;<<li>2020 National Postdoctoral Forum on the Development and Application of Artificial Intelligence, Tianjin, China. Excellence Award. <a href="https://github.com/Li-Chongyi/PAPERS/blob/master/%E5%8D%9A%E5%90%8E%E4%BC%98%E7%A7%80%E5%A5%96.pdf">PDF</a></li>&ndash;&gt;-->
<!--<li>Distinguished Dissertation Award of Beijing Society of Image and Graphics, 2018. <a href="http://www.bsig.org.cn/detail/2316">Media</a></li>-->

<!--&lt;!&ndash;<li>Bohai Securities Fellowship, 2017.</li>-->
<!--<li>"Outstanding Graduate Student" in Tianjin University, 2018.-->
<!--<li>"Merit Student" in Tianjin University, 2017.</li>-->
<!--<li>"Advanced Individual" in the creative working, 2017.</li>-->
<!--<li>China Scholarship Council (CSC) scholarships, 2016.</li>-->
<!--<li>The First Class Academic Scholarship in Tianjin University, 2015, 2016.</li><embed src="https://sumanbogati.github.io/sample.pdf" type="application/pdf" />-->
<!--<li>"Advanced Individual" in international exchange, 2015.</li>-->
<!--<li>"Advanced Individual" in the creative working, 2015.</li>&ndash;&gt;-->

<!--</ul>-->
<!--<br>-->
<!--<hr />-->


<!-- <h2>-->
<!--<a id="new-page" class="anchor" href="#new-page" aria-hidden="true"><span class="octicon octicon-link"></span></a>Professional Service:</h2>-->

<!--<ul>-->

<!--<br><strong>Memberships</strong></br>-->
<!--2023/02- : IEEE Senior Member</br>-->


<!--<br><strong>Associate Editor</strong></br>-->
<!--2023/01- : IEEE Transactions on Circuits and Systems for Video Technology (IF: 5.859)</br>-->
<!--2022/05- : IEEE Journal of Oceanic Engineering (IF: 3.554)</br>-->
<!--2022/01- : Neurocomputing (IF: 5.719)</br>-->
<!--2021/01- : Springer Journal of Signal, Image and Video Processing (IF: 1.794)</br>-->

<!--<br><strong>Guest Editor</strong></br>-->
<!--International Journal of Computer Vision (Lead Guest Editor) (IF: 13.369)</br>-->
<!--IEEE Journal of Oceanic Engineering (Lead Guest Editor) (IF: 3.554)</br>-->
<!--Signal Processing: Image Communication (Management Guest Editor) (IFÔºö2.779)</br>-->
<!--Multimedia Tools and Applications (IF: 2.313)</br>-->
<!--Frontiers in Signal Processing</br>-->

<!--<br><strong>Area Chair</strong></br>-->
<!--BMVC 2022</br>-->

<!--<br><strong>Co-organizer</strong></br>-->
<!--2nd CVPR Workshop on Mobile Intelligent Photography & Imaging (MIPI) 2023</br>-->
<!--1st ECCV Workshop on Mobile Intelligent Photography & Imaging (MIPI) 2022</br>-->
<!--IEEE Workshop on Multimedia Signal Processing (MMSP) 2022</br>-->
<!--&lt;!&ndash;Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC) 2019</br>&ndash;&gt;-->

<!--<br><strong>Senior Program Committee (Meta-Reviewers)</strong></br>-->
<!--AAAI 2022, 2023</br>-->
<!--&lt;!&ndash;-->
<!--<br><strong>Reviewer</strong></br>-->
<!--<li><strong>IEEE</strong>:</li>TPAMI, TIP, TCyber, TCSVT, TNNLS, TMM, TB, TIM, TGARS, TITS, TCSVT II: Express Briefs, ACCESS, SPL, JOE, JBHI, J-STARS, MultiMedia-->
<!--<li><strong>Elsevier</strong>:</li> CVIU, JOE, DSP, Neurocomputing, PRL; SPIC, JCG; Knowledge-based Systems-->
<!--<li><strong>Springer</strong>:</li> IJCV, VC, SCIS,  MVA,  EURASIP JIVP-->
<!--<li><strong>ACM</strong>:</li> Computing Surveys-->
<!--<li><strong>IET</strong>:</li> CV-->
<!--<li><strong>SPIE</strong>:</li> JEI-->
<!--<li><strong>Conference</strong>:</li>ICPR 2018; ACM MM 2019;ICME 2020; ACM MM2020; MICCAI 2020; AAAI 2021; CVPR 2021; IJCAI 2021;ICME 2021; MICCAI 2021; ACM MM2021; ICCV2021; NeurIPS2021; ICLR2022; CVPR2022-->
<!--&ndash;&gt;-->

<!--</ul>-->
<!--<br>-->
<!--<hr />-->



<!-- <h2>-->
<!--<a id="new-page" class="anchor" href="#new-page" aria-hidden="true"><span class="octicon octicon-link"></span></a>Supervision and Teaching:</h2>-->
<!--<ul>-->
<!--<li>Ph.D.: Haoying Li (Zhejiang University),  Visiting Scholar: Old Films Restoration, NTU, 08/2022-present, Co-supervised with Cavan</li>-->
<!--<li>M.E.: Jixin Zhao (Tianjin University),  Intern: Video Denoising, NTU, 08/2022-present, Co-supervised with Cavan</li>-->
<!--<li>B.E.: Yihang Luo (Nanyang Technological University),  Intern: Nighttime Ghost Removal, NTU, 08/2022-present, Co-supervised with Cavan</li>-->
<!--<li>M.E.: Zhexin Liang (Zhejiang University),  AI Major Project: Backlit Image Enhancement, NTU, 01/2022-present, Co-supervised with Cavan</li>-->
<!--<li>M.E.: Yuekun Dai (Peking University),  AI Major Project: Nighttime Flare Removal, NTU, 08/2021-present, Co-supervised with Cavan</li>-->
<!--<li>Ph.D.: Jingming He (Shenzhen University), Underwater Object Detection, CityU, Co-supervised with Shiqi and Sam</li>-->
<!--<li>Ph.D.: Fuzhao Ou (Guangzhou University), Face Image Quality Assessment, CityU, Co-supervised with Shiqi and Sam</li>-->

<!--<li>Teaching Assistant, NTU CE6126: MSAI Advanced Computer Vision, NTU, Fall 2020 </li>-->
<!--</ul>-->
<!--<br>-->
<!--<hr />-->


<!-- <h2>-->
<!--<a id="new-page" class="anchor" href="#new-page" aria-hidden="true"><span class="octicon octicon-link"></span></a>Alumni:</h2>-->
<!--<ul>-->

<!--<li>Zurang Liu (Beijing University of Posts and Telecommunications), Project: Deep Image Harmonization, AI Master@NTU, 01/2021-04/2022, Now: Engineer@ByteDance, SG, Co-supervised with Cavan</li>-->
<!--<li>Sihao Chen, Project: Learning to See in the Dark <a href="https://drive.google.com/file/d/12Vu-n2Kw3DV3qa6VfOVTpbyy8TGfRIQz/view?usp=sharing">[Final Report&#45;&#45;Video (A+)]</a>, FYP of Computer Science@NTU, 06/2020-06/2021, Now: Engineer@Shopee, SG. Sihao's project is awarded the <strong>2021 Global Undergraduate Awards</strong> for his entry 'Learning to See in the Dark - Low Light Image Enhancement'.  <a href="https://undergraduateawards.com/" target="_blank"><font color="#ff0000">[The Global Undergraduate Awards]</font></a><a href="https://www.ntu.edu.sg/scse/news-events/news/detail/scse-s-chen-sihao-(computer-science-year-4)-makes-a-historical-first-win-at-the-global-undergraduate-awards-2021" target="_blank"><font color="#ff0000">[NTU News]</font></a>Co-supervised with Cavan</li>-->
<!--<li>Qiming Ai (University of Science and Technology of China),  Project: Deep Photo Enhancement,  AI Master@NTU, 01/2020-12/2020, Co-supervised with Cavan</li>-->
<!--<li>M.E.: Xingshu Wang (Beijing University of Posts and Telecommunications),  Project: Reference-Based Image Super-Resolution, ANU, Co-supervised with Saeed</li>	</li>-->
<!--<li>M.E.: Yuheng Shi (Nanjing University of Posts and Telecommunications),  Project: Hand Gesture Recognition, ANU, Co-supervised with Saeed</li>-->

<!--</ul>-->
<!--<br>-->
<!--<hr />-->

<!--<h2>-->
<!--<a id="reaserch-page" class="anchor" href="#reaserch-page" aria-hidden="true"><span class="octicon octicon-link"></span></a>Miscellaneous:</h2>-->


<!--<ul>-->
<!--<li><a href="https://unsplash.com/"><font color="#1C86EE">Unsplash</font></a></li>-->
<!--<li><a href="https://pngtree.com/"><font color="#1C86EE">Pngtree</font></a></li>-->
<!--<li><a href="https://www.wordclouds.com/"><font color="#1C86EE">WordClouds</font></a></li>-->
<!--<li><a href="https://emojipedia.org/"><font color="#1C86EE">Emojipedia</font></a></li>-->
<!--<li><a href="https://film-grab.com/"><font color="#1C86EE">FilmGrab</font></a></li>-->
<!--<li><a href="https://deviparikh.medium.com/how-we-write-rebuttals-dc84742fece1/"><font color="#1C86EE">How we write rebuttals</font></a></li>-->
<!--<li><a href="http://www-net.cs.umass.edu/kurose/writing/intro-style.html"><font color="#1C86EE">Writing a good introduction</font></a></li>-->
<!--<li><a href="https://www.computer.org/publications/tech-news/trends/deep-learning-vs-machine-learning-whats-the-difference?source=cssocial"><font color="#1C86EE">Deep Learning vs Machine Learning: What‚Äôs the Difference</font></a></li>-->
<!--</ul>-->
<!--<br>-->




</section>

</div>

</body>






